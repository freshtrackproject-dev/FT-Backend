services:
  - type: web
    name: freshtrack-backend
    env: docker
    plan: free
    region: singapore
    autoDeploy: true

    # Docker setup for Node service
    dockerfilePath: ./Dockerfile
    dockerCommand: node server.js

    # Environment variables for Node service
    envVars:
      - key: NODE_ENV
        value: production
      - key: PORT
        value: 10000
      - key: INFERENCE_URL
        # The internal service name + port that will be reachable in the Render network
        value: https://freshtrack-backend-1.onrender.com/infer
      - key: STORAGE_PATH
        value: /app/data/storage_data.json

    healthCheckPath: /health

    autoDeploy: true
    branch: main

  - type: web
    name: freshtrack-backend-1
    env: docker
    plan: free
    region: singapore
    autoDeploy: true

    # Docker setup for Python service
    dockerfilePath: ./Dockerfile.python
    dockerCommand: /app/tools/download_and_run.sh

    # Environment variables for Python service
    envVars:
      - key: MODEL_URL
        value: https://raw.githubusercontent.com/101star101/freshtrack-backend/main/models/best.pt
      - key: PORT
        value: 8001
      - key: CONF_THRESHOLD
        value: 0.25
      - key: IOU_THRESHOLD
        value: 0.5
      - key: MAX_DET
        value: 100

    healthCheckPath: /health
    name: freshtrack-backend-1
    env: docker
    plan: free
    region: singapore
    autoDeploy: true

    # Docker setup for Python inference service
    dockerfilePath: ./Dockerfile.python
    dockerCommand: uvicorn tools.inference_service:app --host 0.0.0.0 --port 8001

    envVars:
      - key: PORT
        value: 8001
      - key: MODEL_PATH
        value: /app/models/best.pt
      - key: MODEL_URL
        # If you prefer to download the model at container start instead of baking it into the image,
        # set MODEL_URL to a publicly accessible or presigned URL (S3, GCS, etc.).
        value: ""

    healthCheckPath: /health

    autoDeploy: true
    branch: main
